{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d104b2f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-07T00:02:24.899053Z",
     "iopub.status.busy": "2023-04-07T00:02:24.898448Z",
     "iopub.status.idle": "2023-04-07T00:03:21.822312Z",
     "shell.execute_reply": "2023-04-07T00:03:21.820798Z"
    },
    "papermill": {
     "duration": 56.944411,
     "end_time": "2023-04-07T00:03:21.831763",
     "exception": false,
     "start_time": "2023-04-07T00:02:24.887352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/tokenlabel/training_tk4517.txt\n",
      "/kaggle/input/tokenlabel/aps360_testing_labels.txt\n",
      "/kaggle/input/tokenlabel/aps360_validation_labels.txt\n",
      "/kaggle/input/dataset/aug_labels.tsv\n",
      "/kaggle/input/dataset/aug_images.pt\n",
      "(22804, 1)\n",
      "This is the first label:  ['a very typical bus station']\n",
      "torch.Size([22804, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import csv\n",
    "import torchvision\n",
    "import torchtext\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchtext.vocab as vocab\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as F\n",
    "from torchtext import data\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchtext.data\n",
    "from torch.utils.data import DataLoader\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction, corpus_bleu\n",
    "import torchtext\n",
    "import pandas as pd\n",
    "import torchtext.datasets as datasets\n",
    "import math\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "    \n",
    "data = pd.read_csv('/kaggle/input/dataset/aug_labels.tsv', sep='\\t')\n",
    "#Panda adds a random column to the data so do:\n",
    "data = data.drop(columns='Unnamed: 0')\n",
    "\n",
    "print(data.shape) # >>> should be like (22803,1) or smth\n",
    "\n",
    "#Convert the dataframe to a list\n",
    "\n",
    "labels = data.values.tolist() #you now have a list of the labels\n",
    "print(\"This is the first label: \", labels[0])\n",
    "\n",
    "\n",
    "images = torch.load('/kaggle/input/dataset/aug_images.pt') \n",
    "print(images.shape) #should be the 22803,3,224,224\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "761f1380",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T00:03:21.851547Z",
     "iopub.status.busy": "2023-04-07T00:03:21.850540Z",
     "iopub.status.idle": "2023-04-07T00:03:22.128087Z",
     "shell.execute_reply": "2023-04-07T00:03:22.126527Z"
    },
    "papermill": {
     "duration": 0.291551,
     "end_time": "2023-04-07T00:03:22.131302",
     "exception": false,
     "start_time": "2023-04-07T00:03:21.839751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a custom class to create a dataset from an array of tensors\n",
    "class TensorDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        return x\n",
    "\n",
    "# Create arrays for each of the datasets\n",
    "training = []\n",
    "validation = []\n",
    "testing = []\n",
    "\n",
    "# Populate each of the arrays with the images\n",
    "\n",
    "for i in range(0,4517):\n",
    "    training.append(images[i])\n",
    "\n",
    "for n in range(5000, 5350):\n",
    "    validation.append(images[n])\n",
    "\n",
    "for m in range(5350, 5701):\n",
    "    testing.append(images[n])\n",
    "    \n",
    "#for index in range(5701, 10702):\n",
    "    #training.append(images[index])\n",
    "\n",
    "#for ind in range(11402, 16403):\n",
    "    #training.append(images[ind])\n",
    "\n",
    "#for inde in range(17103, 22104):\n",
    "    #training.append(images[inde])\n",
    "    \n",
    "# Adding labels\n",
    "training_labels = []\n",
    "validation_labels = []\n",
    "testing_labels = []\n",
    "\n",
    "for i in range(0,4517):\n",
    "    training_labels.append(labels[i])\n",
    "\n",
    "for n in range(5000, 5350):\n",
    "    validation_labels.append(labels[n])\n",
    "\n",
    "for m in range(5350, 5701):\n",
    "    testing_labels.append(labels[m])\n",
    "    \n",
    "#for index in range(5701, 10702):\n",
    "    #training_labels.append(labels[index])\n",
    "\n",
    "#for ind in range(11402, 16403):\n",
    "    #training_labels.append(labels[ind])\n",
    "\n",
    "#for inde in range(17103, 22104):\n",
    "    #training_labels.append(labels[inde])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35c3ef9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T00:03:22.148630Z",
     "iopub.status.busy": "2023-04-07T00:03:22.148099Z",
     "iopub.status.idle": "2023-04-07T00:07:26.695912Z",
     "shell.execute_reply": "2023-04-07T00:07:26.693021Z"
    },
    "papermill": {
     "duration": 244.561404,
     "end_time": "2023-04-07T00:07:26.700381",
     "exception": false,
     "start_time": "2023-04-07T00:03:22.138977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache/glove.6B.zip: 862MB [02:39, 5.40MB/s]                           \n",
      "100%|█████████▉| 399999/400000 [00:54<00:00, 7307.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['caption', 'a', 'very', 'typical', 'bus', 'station', 'sierra', 'looked', 'stunning', 'in']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torchtext.vocab as vocab\n",
    "\n",
    "# Define the tokenizer (e.g. split on whitespace)\n",
    "tokenizer = lambda x: x.split()\n",
    "\n",
    "# Load the data into a pandas dataframe\n",
    "df = pd.read_csv('/kaggle/input/dataset/aug_labels.tsv', delimiter='\\t', header=None, names=['caption'])\n",
    "\n",
    "# Apply the tokenizer to the 'caption' column\n",
    "df['caption'] = df['caption'].apply(tokenizer)\n",
    "\n",
    "# Build the vocabulary\n",
    "glooooove = vocab.GloVe(name='6B', dim=300)\n",
    "vocab1 = vocab.vocab(glooooove.stoi)\n",
    "vocab1.append_token('<pad>')\n",
    "vocab1.append_token('<start>')\n",
    "vocab1.append_token('<end>')\n",
    "vocab1.append_token('<unk>')\n",
    "vocab1.append_token('the')\n",
    "word_to_idx = {word: i for i, word in enumerate(vocab1.get_itos())}\n",
    "\n",
    "# Convert the data to a PyTorch tensor\n",
    "#captions = torch.tensor([[word_to_idx.get(word, 0) for word in caption] for caption in df['caption']])\n",
    "\n",
    "words = [word for caption in df['caption'] for word in caption]\n",
    "print(words[:10])\n",
    "\n",
    "# Print the resulting tensor and its shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77c6e801",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T00:07:26.986530Z",
     "iopub.status.busy": "2023-04-07T00:07:26.985903Z",
     "iopub.status.idle": "2023-04-07T00:07:27.106113Z",
     "shell.execute_reply": "2023-04-07T00:07:27.104495Z"
    },
    "papermill": {
     "duration": 0.266018,
     "end_time": "2023-04-07T00:07:27.109559",
     "exception": false,
     "start_time": "2023-04-07T00:07:26.843541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "myfile = open(\"/kaggle/input/tokenlabel/training_tk4517.txt\")\n",
    "list2 = []\n",
    "\n",
    "for i in range (4517):\n",
    "    arr = []\n",
    "    arr = myfile.readline().split(' ')\n",
    "    \n",
    "    for k in range (len(arr)):\n",
    "        if (arr[k] == ''):\n",
    "            arr.remove('')\n",
    "    \n",
    "    for j in range (len(arr)):\n",
    "        if (arr[j] == ''):\n",
    "            arr.remove('')\n",
    "        arr[j] = arr[j].strip()\n",
    "        arr[j] = int(arr[j].strip(\"\\n\"))\n",
    "    \n",
    "    #print (arr,\"kekw\")\n",
    "    arr = torch.Tensor(arr)\n",
    "        \n",
    "    list2.append(arr)\n",
    "    \n",
    "    \n",
    "#print(list2)\n",
    "    #tensors = torch.Tensor(lists)\n",
    "    #tensors.append(torch.stack(lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c549d3aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T00:07:27.396627Z",
     "iopub.status.busy": "2023-04-07T00:07:27.394946Z",
     "iopub.status.idle": "2023-04-07T00:07:27.422664Z",
     "shell.execute_reply": "2023-04-07T00:07:27.421528Z"
    },
    "papermill": {
     "duration": 0.176324,
     "end_time": "2023-04-07T00:07:27.426527",
     "exception": false,
     "start_time": "2023-04-07T00:07:27.250203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "myfile = open(\"/kaggle/input/tokenlabel/aps360_validation_labels.txt\")\n",
    "list2 = []\n",
    "\n",
    "for i in range (350):\n",
    "    arr = []\n",
    "    arr = myfile.readline().split(' ')\n",
    "    \n",
    "    for k in range (len(arr)):\n",
    "        if (arr[k] == ''):\n",
    "            arr.remove('')\n",
    "    \n",
    "    for j in range (len(arr)):\n",
    "        if (arr[j] == ''):\n",
    "            arr.remove('')\n",
    "        arr[j] = arr[j].strip()\n",
    "        arr[j] = int(arr[j].strip(\"\\n\"))\n",
    "    \n",
    "    #print (arr,\"kekw\")\n",
    "    arr = torch.Tensor(arr)\n",
    "        \n",
    "    list2.append(arr)\n",
    "    \n",
    "#print (list2, \"hiii\")\n",
    "validation_labels = list2\n",
    "\n",
    "        \n",
    "    #tensors = torch.Tensor(lists)\n",
    "    #tensors.append(torch.stack(lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f840017",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T00:07:27.878445Z",
     "iopub.status.busy": "2023-04-07T00:07:27.877679Z",
     "iopub.status.idle": "2023-04-07T00:07:27.896196Z",
     "shell.execute_reply": "2023-04-07T00:07:27.895024Z"
    },
    "papermill": {
     "duration": 0.166202,
     "end_time": "2023-04-07T00:07:27.899348",
     "exception": false,
     "start_time": "2023-04-07T00:07:27.733146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "myfile = open(\"/kaggle/input/tokenlabel/aps360_testing_labels.txt\")\n",
    "list2 = []\n",
    "\n",
    "for i in range (350):\n",
    "    arr = []\n",
    "    arr = myfile.readline().split(' ')\n",
    "    \n",
    "    for k in range (len(arr)):\n",
    "        if (arr[k] == ''):\n",
    "            arr.remove('')\n",
    "    \n",
    "    for j in range (len(arr)):\n",
    "        if (arr[j] == ''):\n",
    "            arr.remove('')\n",
    "        arr[j] = arr[j].strip()\n",
    "        arr[j] = int(arr[j].strip(\"\\n\"))\n",
    "    \n",
    "    #print (arr,\"kekw\")\n",
    "    arr = torch.Tensor(arr)\n",
    "        \n",
    "    list2.append(arr)\n",
    "    \n",
    "#print (list2, \"hiii\")\n",
    "testing_labels = list2\n",
    "\n",
    "        \n",
    "    #tensors = torch.Tensor(lists)\n",
    "    #tensors.append(torch.stack(lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1737c458",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T00:07:28.177679Z",
     "iopub.status.busy": "2023-04-07T00:07:28.176211Z",
     "iopub.status.idle": "2023-04-07T00:07:30.894732Z",
     "shell.execute_reply": "2023-04-07T00:07:30.892693Z"
    },
    "papermill": {
     "duration": 2.862523,
     "end_time": "2023-04-07T00:07:30.898389",
     "exception": false,
     "start_time": "2023-04-07T00:07:28.035866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n",
      "350\n"
     ]
    }
   ],
   "source": [
    "# Adding padding to all the tensor version of the captions\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "training_labels = pad_sequence(list2, padding_value = vocab1.get_stoi()['<pad>'])\n",
    "validation_labels = pad_sequence(training_labels, padding_value = vocab1.get_stoi()['<pad>'])\n",
    "testing_labels = pad_sequence(training_labels, padding_value = vocab1.get_stoi()['<pad>'])\n",
    "\n",
    "print(len(training_labels[0]))\n",
    "\n",
    "print(len(training_labels[20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "effce2e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T00:07:31.179701Z",
     "iopub.status.busy": "2023-04-07T00:07:31.179265Z",
     "iopub.status.idle": "2023-04-07T00:07:31.255140Z",
     "shell.execute_reply": "2023-04-07T00:07:31.253699Z"
    },
    "papermill": {
     "duration": 0.218894,
     "end_time": "2023-04-07T00:07:31.258033",
     "exception": false,
     "start_time": "2023-04-07T00:07:31.039139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.0000e+05, 4.0000e+05, 4.0000e+05,  ..., 4.0000e+05, 4.0000e+05,\n",
      "         4.0000e+05],\n",
      "        [3.3200e+02, 6.0320e+03, 4.0000e+05,  ..., 8.0880e+03, 8.9800e+02,\n",
      "         2.0170e+03],\n",
      "        [7.9280e+03, 2.0000e+00, 5.1241e+04,  ..., 3.9260e+03, 8.4900e+02,\n",
      "         1.6032e+04],\n",
      "        ...,\n",
      "        [4.0000e+05, 4.0000e+05, 4.0000e+05,  ..., 4.0000e+05, 4.0000e+05,\n",
      "         4.0000e+05],\n",
      "        [4.0000e+05, 4.0000e+05, 4.0000e+05,  ..., 4.0000e+05, 4.0000e+05,\n",
      "         4.0000e+05],\n",
      "        [4.0000e+05, 4.0000e+05, 4.0000e+05,  ..., 4.0000e+05, 4.0000e+05,\n",
      "         4.0000e+05]])\n"
     ]
    }
   ],
   "source": [
    "#print (list2, \"hiii\")\n",
    "print(training_labels)\n",
    "\n",
    "#training_labels = torch.stack(training_labels)\n",
    "#print(training_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e09c3ece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T00:07:31.538184Z",
     "iopub.status.busy": "2023-04-07T00:07:31.537210Z",
     "iopub.status.idle": "2023-04-07T00:07:31.547097Z",
     "shell.execute_reply": "2023-04-07T00:07:31.545815Z"
    },
    "papermill": {
     "duration": 0.151056,
     "end_time": "2023-04-07T00:07:31.549792",
     "exception": false,
     "start_time": "2023-04-07T00:07:31.398736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the dataloaders using the custom class\n",
    "# Create a dataset from the array of tensors\n",
    "training_data = TensorDataset(training, training_labels)\n",
    "validation_data = TensorDataset(validation, validation_labels)\n",
    "testing_data = TensorDataset(testing, testing_labels)\n",
    "\n",
    "# Create a DataLoader from the dataset\n",
    "# The labels are getting lost in the dataloader, only ending up with the image features tensors\n",
    "train_dataloader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
    "valid_dataloader = DataLoader(validation_data, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(testing_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5771952",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T00:07:31.829687Z",
     "iopub.status.busy": "2023-04-07T00:07:31.828259Z",
     "iopub.status.idle": "2023-04-07T00:10:03.926793Z",
     "shell.execute_reply": "2023-04-07T00:10:03.924421Z"
    },
    "papermill": {
     "duration": 152.246123,
     "end_time": "2023-04-07T00:10:03.930507",
     "exception": false,
     "start_time": "2023-04-07T00:07:31.684384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\r\n",
      "Collecting torch==1.8.0+cu111\r\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting torchtext==0.9.0\r\n",
      "  Downloading torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.8.0+cu111) (4.4.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch==1.8.0+cu111) (1.21.6)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torchtext==0.9.0) (4.64.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchtext==0.9.0) (2.28.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.9.0) (2.1.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.9.0) (2022.12.7)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.9.0) (3.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.9.0) (1.26.14)\r\n",
      "Installing collected packages: torch, torchtext\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 1.13.0+cpu\r\n",
      "    Uninstalling torch-1.13.0+cpu:\r\n",
      "      Successfully uninstalled torch-1.13.0+cpu\r\n",
      "  Attempting uninstall: torchtext\r\n",
      "    Found existing installation: torchtext 0.14.0\r\n",
      "    Uninstalling torchtext-0.14.0:\r\n",
      "      Successfully uninstalled torchtext-0.14.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "torchvision 0.14.0+cpu requires torch==1.13.0, but you have torch 1.8.0+cu111 which is incompatible.\r\n",
      "torchmetrics 0.11.4 requires torch>=1.8.1, but you have torch 1.8.0+cu111 which is incompatible.\r\n",
      "torchaudio 0.13.0+cpu requires torch==1.13.0, but you have torch 1.8.0+cu111 which is incompatible.\r\n",
      "pytorch-lightning 1.9.4 requires torch>=1.10.0, but you have torch 1.8.0+cu111 which is incompatible.\r\n",
      "kornia 0.6.11 requires torch>=1.9.1, but you have torch 1.8.0+cu111 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed torch-1.8.0+cu111 torchtext-0.9.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U torch==1.8.0+cu111 torchtext==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13b53f62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T00:10:04.342311Z",
     "iopub.status.busy": "2023-04-07T00:10:04.341839Z",
     "iopub.status.idle": "2023-04-07T00:10:06.697870Z",
     "shell.execute_reply": "2023-04-07T00:10:06.696527Z"
    },
    "papermill": {
     "duration": 2.564462,
     "end_time": "2023-04-07T00:10:06.702134",
     "exception": false,
     "start_time": "2023-04-07T00:10:04.137672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torchtext 0.9.0\r\n",
      "Uninstalling torchtext-0.9.0:\r\n",
      "  Successfully uninstalled torchtext-0.9.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall torchtext --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "525ce4d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T00:10:07.115175Z",
     "iopub.status.busy": "2023-04-07T00:10:07.114261Z",
     "iopub.status.idle": "2023-04-07T00:10:22.059056Z",
     "shell.execute_reply": "2023-04-07T00:10:22.057625Z"
    },
    "papermill": {
     "duration": 15.156909,
     "end_time": "2023-04-07T00:10:22.062393",
     "exception": false,
     "start_time": "2023-04-07T00:10:06.905484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.8.0 in /opt/conda/lib/python3.7/site-packages (1.8.0+cu111)\r\n",
      "Collecting torchtext==0.9.0\r\n",
      "  Using cached torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.8.0) (4.4.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch==1.8.0) (1.21.6)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchtext==0.9.0) (2.28.2)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torchtext==0.9.0) (4.64.1)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.9.0) (1.26.14)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.9.0) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.9.0) (2022.12.7)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext==0.9.0) (2.1.1)\r\n",
      "Installing collected packages: torchtext\r\n",
      "Successfully installed torchtext-0.9.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.8.0 torchtext==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf614438",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T00:10:22.583420Z",
     "iopub.status.busy": "2023-04-07T00:10:22.582840Z",
     "iopub.status.idle": "2023-04-07T00:10:22.594759Z",
     "shell.execute_reply": "2023-04-07T00:10:22.593234Z"
    },
    "papermill": {
     "duration": 0.333807,
     "end_time": "2023-04-07T00:10:22.597889",
     "exception": false,
     "start_time": "2023-04-07T00:10:22.264082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderCNN(nn.Module):\n",
    "    def __init__(self, embed_size, train_CNN=False):\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        self.train_CNN = train_CNN\n",
    "        self.inception = models.inception_v3(pretrained=True, aux_logits=False)\n",
    "        self.inception.fc = nn.Linear(self.inception.fc.in_features, embed_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        features = self.inception(images)\n",
    "        \n",
    "        for name, param in self.inception.named_parameters():\n",
    "            if \"fc.weight\" in name or \"fc.bias\" in name:\n",
    "                param.requires_grad = True\n",
    "                \n",
    "            else:\n",
    "                param.requires_grad = self.train_CNN\n",
    "                \n",
    "        return self.dropout(self.relu(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6d9973e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T00:10:22.997004Z",
     "iopub.status.busy": "2023-04-07T00:10:22.996492Z",
     "iopub.status.idle": "2023-04-07T00:10:23.032715Z",
     "shell.execute_reply": "2023-04-07T00:10:23.031145Z"
    },
    "papermill": {
     "duration": 0.241017,
     "end_time": "2023-04-07T00:10:23.035849",
     "exception": false,
     "start_time": "2023-04-07T00:10:22.794832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, features, captions): # features come from CNN, captions are the ground truth\n",
    "        embeddings = self.dropout(self.embed(captions))\n",
    "        embeddings = torch.cat((features.unsqueeze(0), embeddings), dim=0)\n",
    "        hiddens, _ = self.lstm(embeddings)\n",
    "        outputs = self.linear(hiddens)\n",
    "        return outputs\n",
    "    \n",
    "class CNN_RNN(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers):\n",
    "        super(CNN_RNN, self).__init__()\n",
    "        self.encoderCNN = EncoderCNN(embed_size)\n",
    "        self.decoderRNN = DecoderRNN(embed_size, hidden_size, vocab_size, num_layers)\n",
    "        \n",
    "    def forward(self, images, captions):\n",
    "        features = self.encoderCNN(images)\n",
    "        outputs = self.decoderRNN(features, captions)\n",
    "        return outputs\n",
    "    \n",
    "    def caption_image(self, image, vocabulary, max_lengths=50):\n",
    "        result_caption = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x = self.encoderCNN(image).unsqueeze(0)\n",
    "            states = None\n",
    "            \n",
    "            for _ in range(max_lengths):\n",
    "                hidden, states = self.decoderRNN.lstm(x, states)\n",
    "                output = self.decoderRNN.linear(hidden.squeeze(0))\n",
    "                predicted = output.argmax(1)\n",
    "                \n",
    "                result_caption.append(predicted.item())\n",
    "                x = self.decoderRNN.embed(predicted).unsqueeze(0)\n",
    "                \n",
    "                if vocabulary.itos[predicted.item()] == \"<EOS>\":\n",
    "                    break\n",
    "                #if vocabulary.get_itos()[predicted.item()] == \"<end>\":\n",
    "                #    break\n",
    "                    \n",
    "        #return [vocabulary.get_itos()[idx] for idx in result_caption]\n",
    "        return [vocabulary.itos[idx] for idx in result_caption]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88b005e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-07T00:10:23.435968Z",
     "iopub.status.busy": "2023-04-07T00:10:23.435108Z",
     "iopub.status.idle": "2023-04-07T00:10:23.748021Z",
     "shell.execute_reply": "2023-04-07T00:10:23.745288Z"
    },
    "papermill": {
     "duration": 0.514807,
     "end_time": "2023-04-07T00:10:23.750767",
     "exception": true,
     "start_time": "2023-04-07T00:10:23.235960",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x7c885e2614d0>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20/3693623601.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#only have training labels,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "it = iter(train_dataloader)\n",
    "print(it)\n",
    "\n",
    "x,y = next(it) #only have training labels,\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a938f74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-06T23:25:01.354438Z",
     "iopub.status.busy": "2023-04-06T23:25:01.354043Z",
     "iopub.status.idle": "2023-04-06T23:25:01.380378Z",
     "shell.execute_reply": "2023-04-06T23:25:01.378610Z",
     "shell.execute_reply.started": "2023-04-06T23:25:01.354406Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c4481a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-06T23:37:38.779916Z",
     "iopub.status.busy": "2023-04-06T23:37:38.779481Z",
     "iopub.status.idle": "2023-04-06T23:37:38.804606Z",
     "shell.execute_reply": "2023-04-06T23:37:38.803120Z",
     "shell.execute_reply.started": "2023-04-06T23:37:38.779877Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(train_features[5][0].shape)\n",
    "img = train_features[0].squeeze()\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a298dcd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-06T23:25:14.467649Z",
     "iopub.status.busy": "2023-04-06T23:25:14.466894Z",
     "iopub.status.idle": "2023-04-06T23:25:14.516777Z",
     "shell.execute_reply": "2023-04-06T23:25:14.513494Z",
     "shell.execute_reply.started": "2023-04-06T23:25:14.467506Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "print(\"train_features \", train_features[0].shape)\n",
    "label = train_labels[0]\n",
    "print(f\"Label: {label}\")\n",
    "# Convert the tensor to a PIL image\n",
    "image = transforms.ToPILImage()(train_features[0])\n",
    "\n",
    "# Display the image using Matplotlib\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # Turn off axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca935ac6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-06T23:25:57.605273Z",
     "iopub.status.busy": "2023-04-06T23:25:57.602927Z",
     "iopub.status.idle": "2023-04-06T23:25:57.616350Z",
     "shell.execute_reply": "2023-04-06T23:25:57.615128Z",
     "shell.execute_reply.started": "2023-04-06T23:25:57.605212Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in training_data:\n",
    "    label = training_data.labels[6]\n",
    "    #print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028c1945",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-06T23:10:14.901376Z",
     "iopub.status.idle": "2023-04-06T23:10:14.901675Z",
     "shell.execute_reply": "2023-04-06T23:10:14.901543Z",
     "shell.execute_reply.started": "2023-04-06T23:10:14.901526Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, (img, captions) in enumerate(train_dataloader):\n",
    "    tensor_list = captions[0].tolist()\n",
    "    caption = []\n",
    "    for i in tensor_list:\n",
    "        word = vocab1.get_itos()[int(i)]\n",
    "        caption.append(word)\n",
    "    for i in range(len(caption)):\n",
    "        if caption[i] == \"<end>\":\n",
    "            caption = caption[1:i]\n",
    "            break\n",
    "    caption = ' '.join(caption)\n",
    "    print(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad46e6d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-06T23:10:14.902682Z",
     "iopub.status.idle": "2023-04-06T23:10:14.902990Z",
     "shell.execute_reply": "2023-04-06T23:10:14.902854Z",
     "shell.execute_reply.started": "2023-04-06T23:10:14.902838Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_captions(model, dataloader, vocab):\n",
    "    model.eval()\n",
    "    \n",
    "    # iterate through images and corresponding captions\n",
    "    # print out the correct caption\n",
    "    # follow it with the predicted caption\n",
    "    # use the caption_image() function built into the CNN_RNN class\n",
    "    \n",
    "    for idx, (image, label) in enumerate(dataloader):\n",
    "        # go element by element to convert each index value into the corresponding word in the vocab\n",
    "        tensor_list = label[0].tolist()\n",
    "        caption = []\n",
    "        for i in tensor_list:\n",
    "            word = vocab1.get_itos()[int(i)]\n",
    "            caption.append(word)\n",
    "        for i in range(len(caption)):\n",
    "            if caption[i] == \"<end>\":\n",
    "                caption = caption[1:i]\n",
    "                break\n",
    "        correct_caption = ' '.join(caption)        \n",
    "        prediction = \" \".join(model.caption_image(image, vocab))\n",
    "        \n",
    "        print(\"Correct: \", correct_caption)\n",
    "        print(\"Predicted: \", prediction)\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73012d1c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-06T23:10:14.903922Z",
     "iopub.status.idle": "2023-04-06T23:10:14.904212Z",
     "shell.execute_reply": "2023-04-06T23:10:14.904086Z",
     "shell.execute_reply.started": "2023-04-06T23:10:14.904070Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    step = checkpoint[\"step\"]\n",
    "    return step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad8eded",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-06T23:10:14.905445Z",
     "iopub.status.idle": "2023-04-06T23:10:14.905730Z",
     "shell.execute_reply": "2023-04-06T23:10:14.905606Z",
     "shell.execute_reply.started": "2023-04-06T23:10:14.905590Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed_size = 256\n",
    "hidden_size = 256\n",
    "vocab_size = len(vocab1)\n",
    "num_layers = 1\n",
    "learning_rate = 3e-4\n",
    "num_epochs = 30\n",
    "\n",
    "load_model = False\n",
    "save_model = True\n",
    "\n",
    "model = CNN_RNN(embed_size, hidden_size, vocab_size, num_layers)\n",
    "generate_captions(model, train_dataloader, vocab1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcce98f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-06T23:10:14.906681Z",
     "iopub.status.idle": "2023-04-06T23:10:14.906977Z",
     "shell.execute_reply": "2023-04-06T23:10:14.906844Z",
     "shell.execute_reply.started": "2023-04-06T23:10:14.906828Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample training\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def train_model(train_dataloader, valid_dataloader, batch_size, embed_size, hidden_size, num_layers, learning_rate, num_epochs=30, vocab_size=len(vocab1), dataloader=train_dataloader):\n",
    "    #embed_size = 256\n",
    "    #hidden_size = 256\n",
    "    #vocab_size = len(vocab1)\n",
    "    #num_layers = 1\n",
    "    #learning_rate = 3e-4\n",
    "    #num_epochs = 30\n",
    "    \n",
    "    load_model = False\n",
    "    save_model = True\n",
    "    \n",
    "    train_losses, train_acc, valid_losses, valid_acc = [], [], [], []\n",
    "    epochs = []\n",
    "\n",
    "    model = CNN_RNN(embed_size, hidden_size, vocab_size, num_layers)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=vocab1.get_stoi()[\"<pad>\"])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        #generate_captions(model, train_dataloader, vocab1)\n",
    "        #if save_model:\n",
    "            #checkpoint = {\n",
    "                #\"state_dict\" : model.state_dict(),\n",
    "                #\"optimizer\" : optimizer.state_dict(),\n",
    "                #\"step\" : step\n",
    "            #}\n",
    "            #save_checkpoint(checkpoint)\n",
    "        for idx, (imgs, captions) in enumerate(train_dataloader):\n",
    "            # Generating a sample calculation\n",
    "            tensor_list = captions[0].tolist()\n",
    "            caption = []\n",
    "            for i in tensor_list:\n",
    "                word = vocab1.get_itos()[int(i)]\n",
    "                caption.append(word)\n",
    "            for i in range(len(caption)):\n",
    "                if caption[i] == \"<end>\":\n",
    "                    caption = caption[1:i]\n",
    "                    break\n",
    "            correct_caption = ' '.join(caption)        \n",
    "            prediction = \" \".join(model.caption_image(imgs, vocab1))\n",
    "\n",
    "            print(\"Correct: \", correct_caption)\n",
    "            print(\"Predicted: \", prediction)\n",
    "            \n",
    "            # Calculating loss and accuracy\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(imgs, captions[:-1])\n",
    "            train_loss = criterion(output.reshape(-1, pred.shape[2]), captions.reshape(-1))\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_losses.append(float(train_loss))\n",
    "        \n",
    "        for idx, (imgs, captions) in enumerate(valid_dataloader):\n",
    "            pred = model(imgs, captions[:-1])\n",
    "            val_loss = criterion(output.reshape(-1, pred.shape[2]), captions.reshape(-1))\n",
    "        \n",
    "        valid_losses.append(float(val_loss))\n",
    "        \n",
    "        epochs.append(epoch)\n",
    "        \n",
    "        training_acc = get_accuracy(model, train_dataloader, batch_size)\n",
    "        val_acc = get_accuracy(model, valid_dataloader, batch_size)\n",
    "        \n",
    "        train_acc.append(training_acc)\n",
    "        valid_acc.append(val_acc)\n",
    "        \n",
    "        print(\"Epoch {}: \\tTraining Accuracy: {} Training Loss: {} \\nValidation Accuracy: {} Validation Loss: {}\".format(epoch+1, train_acc[-1], train_losses[-1], valid_acc[-1], valid_losses[-1]))\n",
    "        \n",
    "    # Plotting accuracy graphs and whatnot\n",
    "    plt.title(\"Training and Validation Losses Curve\")\n",
    "    plt.plot(train_losses, label=\"Train\")\n",
    "    plt.plot(valid_losses, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Training and Validation Accuracy Curve\")\n",
    "    plt.plot(epochs, train_acc, label=\"Train\")\n",
    "    plt.plot(epochs, valid_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d928e49",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-06T23:10:14.907857Z",
     "iopub.status.idle": "2023-04-06T23:10:14.908138Z",
     "shell.execute_reply": "2023-04-06T23:10:14.908013Z",
     "shell.execute_reply.started": "2023-04-06T23:10:14.907998Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_model(train_dataloader, valid_dataloader, 1, 512, 512, 3, 3e-4, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bf8a45",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-06T23:10:14.909123Z",
     "iopub.status.idle": "2023-04-06T23:10:14.909398Z",
     "shell.execute_reply": "2023-04-06T23:10:14.909276Z",
     "shell.execute_reply.started": "2023-04-06T23:10:14.909260Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sample code for a potential accuracy function using the BLEU metric\n",
    "def get_accuracy(model, dataloader, batch_size, vocab=vocab1):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ground_truths = []\n",
    "        predictions = []\n",
    "        \n",
    "        for images, captions in dataloader:\n",
    "            # Generate captions for the images\n",
    "            captions_pred = model.generate_caption(images)\n",
    "            \n",
    "            # Convert the predicted captions and true captions to text\n",
    "            predicted_caption = []\n",
    "            actual_caption = []\n",
    "            for i in range(len(captions_pred)):\n",
    "                pred_sentence = [vocab.itos[word] for word in captions_pred[i][1:-1]]\n",
    "                true_sentence = [vocab.itos[word] for word in captions[i][1:-1]]\n",
    "                \n",
    "                # Remove any <pad> tokens from the true sentence\n",
    "                true_sentence = [token for token in true_sentence if token != '<pad>']\n",
    "\n",
    "                predicted_caption.append(pred_sentence)\n",
    "                actual_caption.append(true_sentence)\n",
    "                \n",
    "            # Add the references and hypotheses to the lists\n",
    "            ground_truths.append([true_sentence])\n",
    "            predictions.append(pred_sentence)\n",
    "                \n",
    "    # Compute the BLEU scores\n",
    "    bleu_score = corpus_bleu(ground_truths, predictions)\n",
    "\n",
    "    return bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97071ad",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 491.810336,
   "end_time": "2023-04-07T00:10:26.089591",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-07T00:02:14.279255",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
